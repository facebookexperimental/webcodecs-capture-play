<!doctype html>

<!--
Copyright (c) Meta Platforms, Inc. and affiliates.

This source code is licensed under the MIT license found in the
LICENSE file in the root directory of this source tree.
-->

<head>
    <style>
        .boxed {
            border: 1px solid black;
        }

        .styleform label {
            float: left;
            margin: 5px 10px 5px 10px;
        }

        .styleform input {
            margin: 5px 10px 5px 10px;
        }

        /* this gives space for the label on the left */
        .styleform .clear {
            clear: both;
        }

        /* prevent elements from stacking weirdly */
    </style>
    <title>Test Ultra low latency with WebCodecs ENCODER (by Jordi Cenzano)</title>
</head>

<body onload="initUI();">
    <h1>Test Ultra low latency with Webcodecs: ENCODER</h1>
    <h2>WebCam(v+a) -> Encode -> Mux -> Send -> Server</h2>
    <div class="boxed">
        <div class="styleform">
            <form>
                <h2>Data needed</h2>
                <div class="clear"></div>
                <label id="wtDestData">WT server:<input id="wtServerUrl" type="text"
                        value="https://localhost:4433/moqingest" size="64"></label>
                <div class="clear"></div>
                <label>StreamID:<input id="uploadId" type="text" value="202112241726"></label><label>Old
                    StreamID:</label><input id="oldUploadId" type="text" value="-" readonly>
                <div class="clear"></div>
                <label>Packager type:
                    <select name="packagerType" id="packagerType">
                        <option value="v2" selected>v2 - Binary</option>
                        <option value="v1">v1 - JSON</option>
                    </select>
                </label>
                <div class="clear"></div>
                <label>Max inflight audio requests:<input id="maxInflightAudioRequests" type="text" value="60"></label>
                <div class="clear"></div>
                <label>Max inflight video requests:<input id="maxInflightVideoRequests" type="text" value="39"></label>
                <div class="clear"></div>
                <label>Expiration time for media chunks (except init) (in secs):<input id="uploadMaxAge" type="text"
                        value="120"></label>
                <div class="clear"></div>
                <h3>Video encoding params (h264)</h3>
                <label>Resolution: <input id="videoEncodingWidth" type="text" value="320" size="5"><input
                        id="videoEncodingHeight" type="text" value="180" size="5"></label>
                <label>FrameRate:<input id="videoEncodingFrameRate" type="text" value="30" size="5"></label>
                <label>KeyFrame every (frames):<input id="videoEncodingKeyFrameEvery" type="text" value="60"
                        size="5"></label>
                <label>Bitrate (bps): <input id="videoEncodingBitrateBps" type="text" value="500000" size="8"></label>
                <div class="clear"></div>
                <h3>Audio encoding params (opus)</h3>
                <label>Bitrate (bps): <input id="audioEncodingBitrateBps" type="text" value="32000" size="8"></label>
                <div class="clear"></div>
                <button id="btnStart" type="button" onclick="start();">Start</button>
                <button id="btnStop" type="button" onclick="stop();" disabled>Stop</button>
            </form>
        </div>
    </div>
    <div class="boxed">
        <video height="50%" id="vPreview" autoplay muted></video>
    </div>
    <div class="boxed">
        <h2>Capture(uncompressed domain)</h2>
        <div class="styleform">
            <form>
                <label>First audio TS(ms): <input id="firstAts" type="text" value="" readonly></label>
                <div class="clear"></div>
                <label>First video TS(ms): <input id="firstVts" type="text" value="" readonly></label>
                <div class="clear"></div>
                <label>V-A start diff(ms): <input id="VAdiff" type="text" value="" readonly></label>
                <div class="clear"></div>
                <label>First comp audio TS(ms): <input id="firstCompAts" type="text" value="" readonly></label>
                <div class="clear"></div>
                <label>First comp video TS(ms): <input id="firstCompVts" type="text" value="" readonly></label>
                <div class="clear"></div>
                <label>V-A comp start diff(ms): <input id="VACompdiff" type="text" value="" readonly></label>
                <div class="clear"></div>

            </form>
        </div>
    </div>
    <div class="boxed">
        <h2>Muxer sender</h2>
        <div>
            <h3>Packager Efficiency</h3>
            <div class="styleform">
                <form>
                    <label>Efficiency (%):<input id="uploadStatsPackagerEfficiency" type="text" value="" readonly
                            size="30"></label>
                    <div class="clear"></div>
                </form>
            </div>
            <h3>Inflight</h3>
            <div class="styleform">
                <form>
                    <label>Inflight audio requests:<input id="uploadStatsAudioInflight" type="text" value=""
                            readonly></label>
                    <div class="clear"></div>
                    <label>Inflight video requests:<input id="uploadStatsVideoInflight" type="text" value=""
                            readonly></label>
                    <div class="clear"></div>
                </form>
            </div>
        </div>
    </div>
    <div class="boxed">
        <h2>Dropped data (frames / chunks):</h2>
        <div class="styleform">
            <form>
                <label>Total dropped audio chunks: <input id="totalAudioChunksDropped" type="text" value=""
                        readonly></label>
                <div class="clear"></div>
                <label>Total dropped video chunks: <input id="totalVideoChunksDropped" type="text" value=""
                        readonly></label>
                <div class="clear"></div>
            </form>
        </div>
        <ol id="droppedFrames"></ol>
    </div>
</body>
<script src="../utils/time_checker.js"></script>
<script>
    // Main vars
    const VERBOSE = true;

    // Current TS generated by capture
    let currentAudioTs = undefined;
    let currentVideoTs = undefined;
    let videoOffsetTS = undefined;
    let audioOffsetTS = undefined;

    // Video encoder config
    const videoEncoderConfig = {
        encoderConfig: {
            codec: 'avc1.42001e', // Baseline = 66, level 30 (see: https://en.wikipedia.org/wiki/Advanced_Video_Coding)
            width: 320,
            height: 180,
            bitrate: 1_000_000, // 1 Mbps
            framerate: 30,
            latencyMode: 'realtime', // Sends 1 chunk per frame
        },
        encoderMaxQueueSize: 2,
        keyframeEvery: 60,
    };

    // Audio encoder config
    const audioEncoderConfig = {
        encoderConfig: {
            codec: 'opus', // AAC NOT implemented YET (it is in their roadmap)
            sampleRate: 48000, // To fill later
            numberOfChannels: 1, // To fill later
            bitrate: 32000,
        },
        encoderMaxQueueSize: 10,
    };

    // To keep some stats
    let dropChunksTotals = {};
    let statsHelper = {};

    function returnMax(varName, val) {
        ret = val;
        if (!(varName in statsHelper)) {
            statsHelper[varName] = val;
        } else {
            if (statsHelper[varName] > val) {
                ret = statsHelper[varName];
            } else {
                statsHelper[varName] = val;
            }
        }
        return ret;
    }

    // To keep track of the frame generation time between frame & chunk

    const audioTimeChecker = new TimeChecker("audio");
    const videoTimeChecker = new TimeChecker("video");

    const muxerSenderConfig = {
        audioMaxMaxQueueSizeMs: 200,
        videoMaxMaxQueueSizeMs: 100,

        maxInFlightAudioRequests: 100,
        maxInFlightVideoRequests: 50,

        urlHostPort: '',
        urlPath: '',

        maxAgeChunkS: 120,
    }

    // Current workers
    vStreamWorker = null;
    aStreamWorker = null;
    vEncoderWorker = null;
    aEncoderWorker = null;
    muxerSenderWorker = null;

    // Read & parse QS data
    const queryString = window.location.search;
    console.log("Read querystring: " + queryString);
    const qsParams = new URLSearchParams(queryString);

    function createWorkers() {
        // Create a new workers for video / audio frames capture
        vStreamWorker = new Worker("./v_capture.js");
        aStreamWorker = new Worker("./a_capture.js");

        // Create a new workers for video / audio frames encode
        vEncoderWorker = new Worker("v_encoder.js");
        aEncoderWorker = new Worker("a_encoder.js");

        // Create send worker
        muxerSenderWorker = new Worker("muxer_sender.js");
    }

    function clearUI() {
        document.getElementById('uploadStatsAudioInflight').value = "0";
        document.getElementById('uploadStatsVideoInflight').value = "0";

        document.getElementById('uploadStatsPackagerEfficiency').value = "0";

        document.getElementById('firstVts').value = "";
        document.getElementById('firstAts').value = "";
        document.getElementById('VAdiff').value = "";

        document.getElementById('firstCompVts').value = "";
        document.getElementById('firstCompAts').value = "";
        document.getElementById('VACompdiff').value = "";

        document.getElementById('droppedFrames').innerHTML = '';

        statsHelper = {};
        dropChunksTotals = {};
    }

    function numToStrWithPad(d, length) {
        let r = d.toString();
        while (r.length < length) {
            r = "0" + r;
        }
        return r;
    }

    function initUI() {
        initStreamIDUI();
        initHostUI();
    }

    function initHostUI() {
        const qsHost = qsParams.get('host')
        if (qsHost != undefined) {
            document.getElementById("wtServerUrl").value = qsHost;
        }
    }

    function initStreamIDUI() {
        const d = new Date();
        const sStr = d.getUTCFullYear().toString() + numToStrWithPad(d.getUTCMonth() + 1, 2) + numToStrWithPad(d.getUTCDate(), 2) + numToStrWithPad(d.getUTCHours(), 2) + numToStrWithPad(d.getUTCMinutes(), 2) + numToStrWithPad(d.getUTCSeconds(), 2);
        document.getElementById("uploadId").value = sStr;
    }

    function stop() {
        document.getElementById("btnStart").disabled = false
        document.getElementById("btnStop").disabled = true

        document.getElementById("oldUploadId").value = document.getElementById("uploadId").value;
        initStreamIDUI();

        stopMsg = { type: "stop" };
        aStreamWorker.postMessage(stopMsg);
        vStreamWorker.postMessage(stopMsg);

        vEncoderWorker.postMessage(stopMsg);
        aEncoderWorker.postMessage(stopMsg);

        muxerSenderWorker.postMessage(stopMsg);

        audioTimeChecker.Clear();
        videoTimeChecker.Clear();
    }

    function processWorkerMessage(e) {
        // LOGGING
        if ((e.data.type === "debug") && (VERBOSE === true)) {
            // logging debug
            console.debug(e.data.data);
        } else if (e.data.type === "info") {
            // logging info
            console.log(e.data.data);
        } else if (e.data.type === "error") {
            // logging error
            console.error(e.data.data);
        } else if (e.data.type === "warning") {
            // logging warning
            console.warn(e.data.data);

            // ENCODING
        } else if (e.data.type === "vframe") {
            const vFrame = e.data.data;
            let estimatedDuration = -1;
            if (currentVideoTs == undefined) {
                if (audioOffsetTS == undefined) {
                    // Start video at 0
                    videoOffsetTS = -vFrame.timestamp; // Comp video starts 0
                } else {
                    // Adjust video offset to last audio seen (most probable case since audio startsup faster)
                    videoOffsetTS = -vFrame.timestamp + currentAudioTs + audioOffsetTS; // Comp video starts last audio seen
                }
                updateFirstTS("video", vFrame.timestamp, vFrame.timestamp + videoOffsetTS);
            } else {
                estimatedDuration = vFrame.timestamp - currentVideoTs;
            }
            currentVideoTs = vFrame.timestamp;
            videoTimeChecker.AddItem({ ts: currentVideoTs, compesatedTs: currentVideoTs + videoOffsetTS, estimatedDuration: estimatedDuration, clkms: e.data.clkms });
            // Encode video frame
            vEncoderWorker.postMessage({ type: "vframe", vframe: vFrame }, [vFrame]);
        } else if (e.data.type === "aframe") {
            const aFrame = e.data.data;
            let estimatedDuration = -1;
            if (currentAudioTs == undefined) {
                if (videoOffsetTS == undefined) {
                    // Start audio at 0
                    audioOffsetTS = -aFrame.timestamp; // Comp audio starts 0
                } else {
                    // Adjust audio offset to last video seen
                    audioOffsetTS = -aFrame.timestamp + currentVideoTs + videoOffsetTS; // Comp audio starts last video seen
                }
                updateFirstTS("audio", aFrame.timestamp, aFrame.timestamp + audioOffsetTS);
            } else {
                estimatedDuration = aFrame.timestamp - currentAudioTs;
            }
            currentAudioTs = aFrame.timestamp;
            audioTimeChecker.AddItem({ ts: currentAudioTs, compesatedTs: currentAudioTs + audioOffsetTS, estimatedDuration: estimatedDuration, clkms: e.data.clkms });
            // Encode audio frame
            aEncoderWorker.postMessage({ type: "aframe", aframe: aFrame });

            // DROPPED
        } else if (e.data.type === "dropped") {
            updateDroppedFrame(e.data.data);

            // CHUNKS
        } else if (e.data.type === "vchunk") {
            const chunk = e.data.chunk;
            const metadata = e.data.metadata;
            const seqId = e.data.seqId;

            const itemTsClk = videoTimeChecker.GetItemByTs(chunk.timestamp);
            if (itemTsClk === undefined) {
                console.error(`Not found TS for that initial video frame, this should not happen.  ts: ${chunk.timestamp}, id:${seqId}`);
            } else {
                muxerSenderWorker.postMessage({ type: "vchunk", firstFrameClkms: itemTsClk.clkms, compesatedTs: itemTsClk.compesatedTs, estimatedDuration: itemTsClk.estimatedDuration, seqId: seqId, chunk: chunk, metadata: metadata });
            }
        } else if (e.data.type === "achunk") {
            const chunk = e.data.chunk;
            const metadata = e.data.metadata;
            const seqId = e.data.seqId;

            const itemTsClk = audioTimeChecker.GetItemByTs(chunk.timestamp);
            if (itemTsClk == undefined) {
                console.error(`Not found TS for that initial audio frame, this should not happen. ts: ${chunk.timestamp}, id:${seqId}`);
            } else {
                muxerSenderWorker.postMessage({ type: "achunk", firstFrameClkms: itemTsClk.clkms, compesatedTs: itemTsClk.compesatedTs, seqId: seqId, chunk: chunk, metadata: metadata });
            }

            // CHUNKS STATS
        } else if (e.data.type === "sendstats") {
            updateUploadStats(currentAudioTs, currentVideoTs, e.data.inFlightAudioReqNum, e.data.inFlightVideoReqNum, e.data.efficiencyData);

            // UNKNOWN
        } else {
            console.error("unknown message: " + e.data);
        }
    }

    function updateUploadStats(currentAudioTs, currentVideoTs, inFlightAudioReqNum, inFlightVideoReqNum, packagerEfficiencyData) {
        document.getElementById('uploadStatsAudioInflight').value = `${inFlightAudioReqNum} (${returnMax('inFlightAudioReqNum', inFlightAudioReqNum)})`;
        document.getElementById('uploadStatsVideoInflight').value = `${inFlightVideoReqNum} (${returnMax('inFlightVideoReqNum', inFlightVideoReqNum)})`;

        const effVideo = ((packagerEfficiencyData.video.totalPayloadBytesSent / (packagerEfficiencyData.video.totalPackagerBytesSent + packagerEfficiencyData.video.totalPayloadBytesSent)) * 100).toFixed(2);
        const effAudio = ((packagerEfficiencyData.audio.totalPayloadBytesSent / (packagerEfficiencyData.audio.totalPackagerBytesSent + packagerEfficiencyData.audio.totalPayloadBytesSent)) * 100).toFixed(2);
        const effTotal = (((packagerEfficiencyData.video.totalPayloadBytesSent + packagerEfficiencyData.audio.totalPayloadBytesSent) / (packagerEfficiencyData.video.totalPackagerBytesSent + packagerEfficiencyData.audio.totalPackagerBytesSent + packagerEfficiencyData.video.totalPayloadBytesSent + packagerEfficiencyData.audio.totalPayloadBytesSent)) * 100).toFixed(2);
        const effStr = `${effTotal} (v: ${effVideo}, a: ${effAudio})`;
        document.getElementById('uploadStatsPackagerEfficiency').value = effStr;
    }

    function updateDroppedFrame(droppedFrameData) {
        const list = document.getElementById('droppedFrames');

        const clkms = droppedFrameData.clkms;
        const ts = droppedFrameData.ts;
        const seqId = droppedFrameData.seqId;
        const msg = droppedFrameData.msg;
        const mediaType = droppedFrameData.mediaType;

        if (seqId >= 0) {
            // Is a chunk
            if (!(mediaType in dropChunksTotals)) {
                dropChunksTotals[mediaType] = 1;
            } else {
                dropChunksTotals[mediaType]++;
            }
            if (mediaType == "video") {
                document.getElementById('totalVideoChunksDropped').value = dropChunksTotals[mediaType]
            } else if (mediaType == "audio") {
                document.getElementById('totalAudioChunksDropped').value = dropChunksTotals[mediaType]
            }
        }

        const str = new Date(clkms).toISOString() + " (" + seqId + ")(" + ts + ") " + msg;

        const entry = document.createElement('li');
        entry.appendChild(document.createTextNode(str));
        list.appendChild(entry);
    }

    function updateFirstTS(type, ts, compensatedTs) {
        tsms = (ts / 1000).toFixed(3);
        compensatedTsms = (compensatedTs / 1000).toFixed(3);

        if (type === "video") {
            document.getElementById('firstVts').value = tsms;
            document.getElementById('firstCompVts').value = compensatedTsms;
        } else if (type === "audio") {
            document.getElementById('firstAts').value = tsms;
            document.getElementById('firstCompAts').value = compensatedTsms;
        }
        diffms = document.getElementById('firstVts').value - document.getElementById('firstAts').value
        if (Number.isFinite(diffms / 1000)) {
            document.getElementById('VAdiff').value = (diffms / 1000).toFixed(3);
        }
        diffCompms = document.getElementById('firstCompVts').value - document.getElementById('firstCompAts').value
        if (Number.isFinite(diffCompms)) {
            document.getElementById('VACompdiff').value = diffCompms.toFixed(3);
        }
    }

    function start() {
        currentAudioTs = undefined;
        currentVideoTs = undefined;
        videoOffsetTS = undefined;
        audioOffsetTS = undefined;

        document.getElementById("btnStart").disabled = true
        document.getElementById("btnStop").disabled = false

        clearUI();

        createWorkers();

        // Load video encoding settings
        videoEncoderConfig.encoderConfig.width = parseInt(document.getElementById('videoEncodingWidth').value);
        videoEncoderConfig.encoderConfig.height = parseInt(document.getElementById('videoEncodingHeight').value);
        videoEncoderConfig.encoderConfig.framerate =parseInt( document.getElementById('videoEncodingFrameRate').value);
        videoEncoderConfig.encoderConfig.bitrate = parseInt(document.getElementById('videoEncodingBitrateBps').value);
        videoEncoderConfig.keyframeEvery = parseInt(document.getElementById('videoEncodingKeyFrameEvery').value);

        // Load audio encoding settings
        audioEncoderConfig.encoderConfig.bitrate = parseInt(document.getElementById('audioEncodingBitrateBps').value);

        var constraints = { audio: true, video: { width: 1280, height: 720 } };

        // Get a MediaStream from the webcam.
        navigator.mediaDevices.getUserMedia(constraints)
            .then(mediaStream => {
                // Connect the webcam stream to the video element.
                document.getElementById('vPreview').srcObject = mediaStream;

                // Print messages from the worker in the console
                vStreamWorker.addEventListener('message', function (e) {
                    processWorkerMessage(e);
                });
                aStreamWorker.addEventListener('message', function (e) {
                    processWorkerMessage(e);
                });
                vEncoderWorker.addEventListener('message', function (e) {
                    processWorkerMessage(e);
                });
                aEncoderWorker.addEventListener('message', function (e) {
                    processWorkerMessage(e);
                });
                muxerSenderWorker.addEventListener('message', function (e) {
                    processWorkerMessage(e);
                });

                // Create a MediaStreamTrackProcessor, which exposes frames from the track
                // as a ReadableStream of VideoFrames.
                var vTrack = mediaStream.getVideoTracks()[0];
                var vProcessor = new MediaStreamTrackProcessor(vTrack);
                var vFrameStream = vProcessor.readable;

                var aTrack = mediaStream.getAudioTracks()[0];
                var aProcessor = new MediaStreamTrackProcessor(aTrack);
                var aFrameStream = aProcessor.readable;

                // Initialize encoders
                vEncoderWorker.postMessage({ type: "vencoderini", encoderConfig: videoEncoderConfig.encoderConfig, encoderMaxQueueSize: videoEncoderConfig.encoderMaxQueueSize, keyframeEvery: videoEncoderConfig.keyframeEvery });
                aEncoderWorker.postMessage({ type: "aencoderini", encoderConfig: audioEncoderConfig.encoderConfig, encoderMaxQueueSize: audioEncoderConfig.encoderMaxQueueSize });

                // Transport
                // Get url data
                muxerSenderConfig.urlHostPort = document.getElementById('wtServerUrl').value;
                muxerSenderConfig.urlPath = document.getElementById('uploadId').value;
                muxerSenderConfig.packagerVersion = document.getElementById('packagerType').value;

                // Get Max-age data
                muxerSenderConfig.maxAgeChunkS = parseInt(document.getElementById('uploadMaxAge').value);
                //Get max Inflight requests
                muxerSenderConfig.maxInFlightAudioRequests = parseInt(document.getElementById('maxInflightAudioRequests').value);
                muxerSenderConfig.maxInFlightVideoRequests = parseInt(document.getElementById('maxInflightVideoRequests').value);

                // Initialize muxer - sender
                muxerSenderWorker.postMessage({ type: "muxersendini", muxerSenderConfig: muxerSenderConfig });

                // Transfer the readable stream to the worker.
                vStreamWorker.postMessage({ type: "stream", vStream: vFrameStream }, [vFrameStream]);
                aStreamWorker.postMessage({ type: "stream", aStream: aFrameStream }, [aFrameStream]);
            })
            .catch(err => {
                console.error(err);
            });
    }
</script>